{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contains code from:\n",
    "# Composer - Apache-2.0 license - Copyright 2022 MosaicML Composer authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import transformers\n",
    "import datasets\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from composer.algorithms import FusedLayerNorm, LowPrecisionLayerNorm\n",
    "from composer.callbacks import SpeedMonitor\n",
    "from composer.loggers import ProgressBarLogger, InMemoryLogger\n",
    "from composer.models.huggingface import HuggingFaceModel\n",
    "from composer.metrics import CrossEntropy\n",
    "from composer.optim.scheduler import CosineAnnealingWithWarmupScheduler\n",
    "from composer.utils import module_surgery\n",
    "from composer import Trainer\n",
    "\n",
    "from fastxtend.utils import less_random\n",
    "\n",
    "APEX = BNB = False\n",
    "\n",
    "from transformers.utils import logging as hf_logging\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "hf_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'mosaicml/mpt-7b'\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXTokenizerFast(name_or_path='mosaicml/mpt-7b', vocab_size=50254, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(sample):\n",
    "    return tokenizer(\n",
    "        text=sample['text'],\n",
    "        padding='max_length',\n",
    "    )\n",
    "gutenberg_dataset = datasets.load_dataset('sedthh/gutenberg_english')\n",
    "tokenized_dataset = gutenberg_dataset.map(tokenize_function,\n",
    "                                          batched=True,\n",
    "                                          num_proc=cpu_count(),\n",
    "                                          batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
